{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpIfCtDGJ5q-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Aprendizaje Multietiqueta de Patrones Geométricos en Objetos de Herencia Cultural\n",
    "# Kunisch Features from ResNet architectures\n",
    "## Seminario de Tesis II, Primavera 2022\n",
    "### Master of Data Science. Universidad de Chile.\n",
    "#### Prof. guía: Benjamín Bustos - Prof. coguía: Iván Sipirán\n",
    "#### Autor: Matías Vergara\n",
    "\n",
    "El objetivo de este notebook es extraer features mediante ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Z2do8XKiAQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np, scipy.io\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configuración de dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando device: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "CUDA_ID = 0\n",
    "\n",
    "device = torch.device(f'cuda:{CUDA_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando device: {torch.cuda.get_device_name(device)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configuración de datos y modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Flags para los datos sintéticos\n",
    "# Cada flag está asociada a una o más funciones de data augmentation.\n",
    "# Los datos deben existir previamente \n",
    "# (se generan a partir del notebook split and augmentation)\n",
    "USE_RN50 = False\n",
    "DS_FLAGS = []\n",
    "              # 'ref': [invertX, invertY],\n",
    "              # 'rot': [rotate90, rotate180, rotate270],\n",
    "              # 'crop': [crop] * CROP_TIMES,\n",
    "              # 'blur': [blur],\n",
    "              # 'emboss': [emboss],\n",
    "              # 'randaug': [randaug],\n",
    "              # 'rain': [rain],\n",
    "              # 'elastic': [elastic]\n",
    "                \n",
    "# Las flags crop, randaug, elastic y gausblur \n",
    "# se pueden aplicar más de una vez c/u. \n",
    "# (si no están en DS_FLAGS, serán ignoradas).\n",
    "CROP_TIMES = 1\n",
    "RANDOM_TIMES = 1\n",
    "ELASTIC_TIMES = 1\n",
    "GAUSBLUR_TIMES = 1\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "--Pattern set encontrado en ../patterns/base/0\n",
      "--Labels set encontrado en ../labels/base/0\n",
      "--Modelo encontrado en ../models/resnet/base/resnet18_K0.pth\n",
      "--Features a guardar en ../features/resnet/base/resnet18_K0\n",
      "Fold  1\n",
      "--Pattern set encontrado en ../patterns/base/1\n",
      "--Labels set encontrado en ../labels/base/1\n",
      "--Modelo encontrado en ../models/resnet/base/resnet18_K0.pth\n",
      "--Features a guardar en ../features/resnet/base/resnet18_K1\n",
      "Fold  2\n",
      "--Pattern set encontrado en ../patterns/base/2\n",
      "--Labels set encontrado en ../labels/base/2\n",
      "--Modelo encontrado en ../models/resnet/base/resnet18_K0.pth\n",
      "--Features a guardar en ../features/resnet/base/resnet18_K2\n",
      "Fold  3\n",
      "--Pattern set encontrado en ../patterns/base/3\n",
      "--Labels set encontrado en ../labels/base/3\n",
      "--Modelo encontrado en ../models/resnet/base/resnet18_K0.pth\n",
      "--Features a guardar en ../features/resnet/base/resnet18_K3\n"
     ]
    }
   ],
   "source": [
    "# Esta celda construye la variable data_flags, que lee DS_FLAGS de \n",
    "# la celda anterior y mapea su contenido a distintas rutas de \n",
    "# patrones, etiquetas y outputs\n",
    "MAP_TIMES = {'crop': CROP_TIMES,\n",
    "         'randaug': RANDOM_TIMES,\n",
    "         'elastic': ELASTIC_TIMES,\n",
    "         'gausblur': GAUSBLUR_TIMES\n",
    "}\n",
    "\n",
    "DS_FLAGS = sorted(DS_FLAGS)\n",
    "data_flags = '_'.join(DS_FLAGS) if len(DS_FLAGS) > 0 else 'base'\n",
    "MULTIPLE_TRANSF = MAP_TIMES.keys()\n",
    "COPY_FLAGS = DS_FLAGS.copy()\n",
    "\n",
    "for t in MULTIPLE_TRANSF:\n",
    "    if t in DS_FLAGS:\n",
    "        COPY_FLAGS.remove(t)\n",
    "        COPY_FLAGS.append(t + str(MAP_TIMES[t]))\n",
    "        data_flags = '_'.join(COPY_FLAGS)\n",
    "\n",
    "# Revisión de los folds y creación de diccionario con paths\n",
    "Kfolds = {}\n",
    "\n",
    "for i in range(0, K):\n",
    "    print(\"Fold \", i)\n",
    "    patterns_dir = os.path.join(root_dir, 'patterns',  data_flags, str(i))\n",
    "    labels_dir = os.path.join(root_dir, 'labels', data_flags, str(i))\n",
    "    rn = 50 if USE_RN50 else 18\n",
    "    models_path = os.path.join(root_dir, 'models', 'resnet', data_flags, f'resnet{rn}_K0.pth')\n",
    "    features_dir = os.path.join(root_dir, 'features', 'resnet', data_flags, f'resnet{rn}_K{i}')\n",
    "\n",
    "    if not (os.path.isdir(patterns_dir) and os.path.isdir(labels_dir)):\n",
    "        print(patterns_dir)\n",
    "        print(labels_dir)\n",
    "        raise FileNotFoundError(\"\"\"\n",
    "        No existen directorios de datos para el conjunto de flags seleccionado. \n",
    "        Verifique que el dataset exista y, de lo contrario, llame a Split and Augmentation.\n",
    "        \"\"\")\n",
    "    if not (os.path.isfile(models_path)):\n",
    "        print(models_path)\n",
    "        raise FileNotFoundError(f\"\"\"\n",
    "        No se encontró modelo para el conjunto de flags seleccionado. \n",
    "        Verifique que el modelo exista y, de lo contrario, llame a ResNet Retraining\n",
    "        \"\"\")\n",
    "                                \n",
    "    Kfolds[i] = {\n",
    "        'patterns_dir': patterns_dir,\n",
    "        'labels_dir': labels_dir,\n",
    "        'model_path': models_path,\n",
    "        'features_dir': features_dir\n",
    "    }\n",
    "    \n",
    "    print(\"--Pattern set encontrado en {}\".format(patterns_dir))\n",
    "    print(\"--Labels set encontrado en {}\".format(labels_dir))\n",
    "    print(\"--Modelo encontrado en {}\".format(models_path))\n",
    "    print(\"--Features a guardar en {}\".format(features_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0o5N582LCJI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Vg1C_6mGLET7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PatternDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, build_classification=False, name_cla='output.cla'):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.namefiles = []\n",
    "        \n",
    "        self.classes = sorted(os.listdir(self.root_dir))\n",
    "\n",
    "        for cl in self.classes:\n",
    "            for pat in os.listdir(os.path.join(self.root_dir, cl)):\n",
    "                self.namefiles.append((pat, cl))\n",
    "\n",
    "        print(f'Files:{len(self.namefiles)}')\n",
    "        #self.namefiles = sorted(self.namefiles, key = lambda x: x[0])\n",
    "        \n",
    "        if build_classification:\n",
    "            dictClasses = dict()\n",
    "\n",
    "            for cl in self.classes:\n",
    "                dictClasses[cl] = []\n",
    "\n",
    "            for index, (name, cl) in enumerate(self.namefiles):\n",
    "                #print(index, name, cl)\n",
    "                dictClasses[cl].append((name, index))\n",
    "\n",
    "            with open(name_cla, 'w') as f:\n",
    "                f.write('PSB 1\\n')\n",
    "                f.write(f'{len(self.classes)} {len(self.namefiles)}\\n')\n",
    "                f.write('\\n')\n",
    "                for cl in self.classes:\n",
    "                    f.write(f'{cl} 0 {len(dictClasses[cl])}\\n')\n",
    "                    for item in dictClasses[cl]:\n",
    "                        f.write(f'{item[1]}\\n')\n",
    "                    f.write('\\n')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.namefiles)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.namefiles[index][1], self.namefiles[index][0])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return self.namefiles[index], image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtpuROg8KkAX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title = None):\n",
    "    inp = inp.cpu().detach()\n",
    "    inp = np.squeeze(inp)\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "\n",
    "    plt.imshow(inp)\n",
    "    plt.show()\n",
    "\n",
    "def get_vector(model,layer, dim_embedding, x):\n",
    "\n",
    "  my_embedding = torch.zeros(dim_embedding)\n",
    "\n",
    "  def copy_data(m,i,o):\n",
    "    my_embedding.copy_(o.data.squeeze())\n",
    "\n",
    "  h = layer.register_forward_hook(copy_data)\n",
    "  model(x)\n",
    "  h.remove()\n",
    "\n",
    "  return my_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mvf-0bRuKn64",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracción de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "giJIZA9AKc9y",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:5536\n",
      "Files:78\n",
      "Files:194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavergar/anaconda3/envs/Kunisch_10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mavergar/anaconda3/envs/Kunisch_10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:5574\n",
      "Files:78\n",
      "Files:194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavergar/anaconda3/envs/Kunisch_10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mavergar/anaconda3/envs/Kunisch_10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:5548\n",
      "Files:78\n",
      "Files:194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavergar/anaconda3/envs/Kunisch_10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mavergar/anaconda3/envs/Kunisch_10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:5548\n",
      "Files:78\n",
      "Files:194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavergar/anaconda3/envs/Kunisch_10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mavergar/anaconda3/envs/Kunisch_10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(30)\n",
    "\n",
    "for i in range(0, K):\n",
    "    patterns_dir = Kfolds[i]['patterns_dir']\n",
    "    labels_dir = Kfolds[i]['labels_dir']\n",
    "    model_path = Kfolds[i ]['model_path']\n",
    "    features_dir = Kfolds[i]['features_dir']\n",
    "    \n",
    "    output_train = os.path.join(features_dir, \"augmented_train_df.json\")\n",
    "    output_val = os.path.join(features_dir, \"val_df.json\")\n",
    "    output_test = os.path.join(features_dir, \"test_df.json\")\n",
    "\n",
    "    train_df = pd.read_json(os.path.join(labels_dir, \"augmented_train_df.json\"), orient='index')\n",
    "    val_df = pd.read_json(os.path.join(labels_dir, \"val_df.json\"), orient='index')\n",
    "    test_df = pd.read_json(os.path.join(labels_dir, \"test_df.json\"), orient='index')\n",
    "\n",
    "\n",
    "    my_transform = transforms.Compose([ transforms.Resize(224),\n",
    "                                        #transforms.CenterCrop(224),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize(mean=[0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
    "                        ])\n",
    "\n",
    "    dataTrain = PatternDataset(root_dir=os.path.join(patterns_dir, 'train'), transform=my_transform)\n",
    "    dataVal = PatternDataset(root_dir=os.path.join(patterns_dir, 'val'), transform=my_transform)\n",
    "    dataTest = PatternDataset(root_dir=os.path.join(patterns_dir, 'test'), transform=my_transform)\n",
    "\n",
    "    loaderTrain = DataLoader(dataTrain, shuffle=\"False\")\n",
    "    loaderVal = DataLoader(dataVal, shuffle=\"False\")\n",
    "    loaderTest = DataLoader(dataTest, shuffle=\"False\")\n",
    "\n",
    "    if USE_RN50:\n",
    "        model = models.resnet50(pretrained = True)\n",
    "    else:\n",
    "        model = models.resnet18(pretrained = True)\n",
    "    dim = model.fc.in_features\n",
    "\n",
    "    output_dim = 6\n",
    "    model.fc = nn.Linear(dim, output_dim)\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Carga del modelo en models_path\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(models_path))\n",
    "    except RuntimeError as e:\n",
    "        print('Ignoring \"' + str(e) + '\"')\n",
    "\n",
    "    layer = model._modules.get('avgpool')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    features_train = {}\n",
    "    features_val = {}\n",
    "    features_test = {}\n",
    "\n",
    "\n",
    "    for name, img in loaderTrain:\n",
    "      feat = get_vector(model, layer, dim, img.to(device))\n",
    "      namefile = name[0][0]\n",
    "      code, rest = namefile.split('.')\n",
    "      #print(code)\n",
    "      #imshow(img)\n",
    "      features_train[code] = feat.numpy().tolist()\n",
    "      #features.append(feat.numpy())\n",
    "\n",
    "    for name, img in loaderVal:\n",
    "      feat = get_vector(model, layer, dim, img.to(device))\n",
    "      namefile = name[0][0]\n",
    "      code, rest = namefile.split('.')\n",
    "      #print(code)\n",
    "      #imshow(img) \n",
    "      features_val[code] = feat.numpy().tolist()\n",
    "      #features.append(feat.numpy())\n",
    "\n",
    "    for name, img in loaderTest:\n",
    "      feat = get_vector(model, layer, dim, img.to(device))\n",
    "      namefile = name[0][0]\n",
    "      code, rest = namefile.split('.')\n",
    "      #print(code)\n",
    "      #imshow(img)\n",
    "      features_test[code] = feat.numpy().tolist()\n",
    "    #features = np.vstack(features)\n",
    "    #print(features.shape)\n",
    "\n",
    "    os.makedirs(features_dir, exist_ok=True)\n",
    "\n",
    "    features_train_df = pd.DataFrame.from_dict(features_train, orient='index')\n",
    "    features_val_df = pd.DataFrame.from_dict(features_val, orient='index')\n",
    "    features_test_df = pd.DataFrame.from_dict(features_test, orient='index')\n",
    "\n",
    "    features_train_df.to_json(output_train, orient='index')\n",
    "    features_val_df.to_json(output_val, orient='index')\n",
    "    features_test_df.to_json(output_test, orient='index')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Feature extraction through ResNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e71b54290f847fab071de377e23c1a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d73d1f809b744c92bc67faa4b746a387",
      "placeholder": "​",
      "style": "IPY_MODEL_54320e55151248dea3eb9da3b77113ef",
      "value": "100%"
     }
    },
    "0fe180ddcecc48a0bb7362e52d2a6624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf95fa30f51242c19c9b1b1edf366290",
      "placeholder": "​",
      "style": "IPY_MODEL_73d9d9d424ad4787900fc8b70d07dff3",
      "value": " 44.7M/44.7M [00:00&lt;00:00, 116MB/s]"
     }
    },
    "122480965ce24f6cb394b7e684ee5618": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a0ed400445a48338cff564bca591284": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0e71b54290f847fab071de377e23c1a8",
       "IPY_MODEL_a188994cbb5d4f969e744d80e5af4412",
       "IPY_MODEL_0fe180ddcecc48a0bb7362e52d2a6624"
      ],
      "layout": "IPY_MODEL_5bc8b4dd7b4e4a65a0d136a484f245a9"
     }
    },
    "54320e55151248dea3eb9da3b77113ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bc8b4dd7b4e4a65a0d136a484f245a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73d9d9d424ad4787900fc8b70d07dff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a188994cbb5d4f969e744d80e5af4412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbeb81af857d46349a7341fafa5ff1d3",
      "max": 46830571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_122480965ce24f6cb394b7e684ee5618",
      "value": 46830571
     }
    },
    "cf95fa30f51242c19c9b1b1edf366290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d73d1f809b744c92bc67faa4b746a387": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbeb81af857d46349a7341fafa5ff1d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
